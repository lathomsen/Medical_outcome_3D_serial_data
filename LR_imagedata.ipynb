{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb2d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score\n",
    "import scipy.stats as st\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "pd.set_option('display.max_rows', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ee574",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate confidence interval\n",
    "def get_standard_diviation(values):\n",
    "  mean = np.mean(values)\n",
    "  n = len(values)\n",
    "  s = np.sqrt(np.sum((values-mean)**2)/(n-1))\n",
    "\n",
    "  return s # (mean-2*s, mean+2*s) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b630f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54e068c3",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1051773",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/python_test/Desktop/Speciale/df_MRI_features_12042022\", sep=\",\", header=0)\n",
    "df = df.set_index(\"id\")\n",
    "df = df.drop([\"v1: id\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e522b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP FOR FIRST VERSION (limit amount of features)\n",
    "var_of_interest = [\"v1: Femur (vol)\",\"v1: JWS (approx)\", \"v1: Img Intensity (mean)\", \"v1: Tibial Intensity (mean)\", \"v1: Femur Intensity (mean)\", \n",
    "                   \"v1: Miniscus Intensity (mean)\", \"v1: Entropy Tibial\", \"v1: Entropy Meniscus\",\"v1: Entropy Femur\",\"v1: Closing Femur\",\"v1: Closing Tibial\",\n",
    "                   \"v1: Closing Meniscus\",\"v1: Thick Femur X\",\"v1: Thick Tibial X\",\"v1: Thick Meniscus X\",\n",
    "                   \"v2: Femur (vol)\",\"v2: JWS (approx)\", \"v2: Img Intensity (mean)\", \"v2: Tibial Intensity (mean)\", \"v2: Femur Intensity (mean)\", \n",
    "                   \"v2: Miniscus Intensity (mean)\", \"v2: Entropy Tibial\", \"v2: Entropy Meniscus\",\"v2: Entropy Femur\",\"v2: Closing Femur\",\"v2: Closing Tibial\",\n",
    "                   \"v2: Closing Meniscus\",\"v2: Thick Femur X\",\"v2: Thick Tibial X\",\"v2: Thick Meniscus X\",\n",
    "                   \"v3: Femur (vol)\",\"v3: JWS (approx)\", \"v3: Img Intensity (mean)\", \"v3: Tibial Intensity (mean)\", \"v3: Femur Intensity (mean)\", \n",
    "                   \"v3: Miniscus Intensity (mean)\", \"v3: Entropy Tibial\", \"v3: Entropy Meniscus\",\"v3: Entropy Femur\",\"v3: Closing Femur\",\"v3: Closing Tibial\",\n",
    "                   \"v3: Closing Meniscus\",\"v3: Thick Femur X\",\"v3: Thick Tibial X\",\"v3: Thick Meniscus X\", 'y']\n",
    "#var_of_interest = [\"v1: Patella (vol)\",\"v1: Medial Tibial (vol)\",\"v1: Lateral Tibial (vol)\",\"v1: Medial Femur (vol)\",\n",
    " #                 \"v1: Lateral Femur (vol)\",\"v1: Medial Miniscus (vol)\",\"v1: Lateral Miniscus (vol)\",\"v1: JWS (approx)\", \n",
    "  #                \"v1: Img Intensity (mean)\",\"v1: Femur Intensity (median)\",\"v1: Miniscus Intensity (median)\",\"v1: Entropy Tibial\",\n",
    "   #               \"v1: Entropy Meniscus\",\"v1: Entropy Femur\",\"v1: Closing Femur\",\"v1: Closing Tibial\",\"v1: Closing Meniscus\",\n",
    "    #              \"v1: Thick Femur X\",\"v1: Thick Femur Y\",\"v1: Thick Femur Z\",\"v1: Thick Tibial Y\",\"v1: Thick Tibial Z\",\n",
    "     #             \"v1: Thick Meniscus X\",\"v1: Thick Meniscus Y\",\n",
    "      #            \"v2: Patella (vol)\",\"v2: Medial Tibial (vol)\",\"v2: Lateral Tibial (vol)\",\"v2: Medial Femur (vol)\",\n",
    "       #           \"v2: Lateral Femur (vol)\",\"v2: Medial Miniscus (vol)\",\"v2: Lateral Miniscus (vol)\",\"v2: JWS (approx)\", \n",
    "        #          \"v2: Img Intensity (mean)\",\"v2: Femur Intensity (median)\",\"v2: Miniscus Intensity (median)\",\"v2: Entropy Tibial\",\n",
    "         #         \"v2: Entropy Meniscus\",\"v2: Entropy Femur\",\"v2: Closing Femur\",\"v2: Closing Tibial\",\"v2: Closing Meniscus\",\n",
    "          #        \"v2: Thick Femur X\",\"v2: Thick Femur Y\",\"v2: Thick Femur Z\",\"v2: Thick Tibial Y\",\"v2: Thick Tibial Z\",\n",
    "           #       \"v2: Thick Meniscus X\",\"v2: Thick Meniscus Y\",\n",
    "            #      \"v3: Patella (vol)\",\"v3: Medial Tibial (vol)\",\"v3: Lateral Tibial (vol)\",\"v3: Medial Femur (vol)\",\n",
    "             #     \"v3: Lateral Femur (vol)\",\"v3: Medial Miniscus (vol)\",\"v3: Lateral Miniscus (vol)\",\"v3: JWS (approx)\",\n",
    "              #    \"v3: Img Intensity (mean)\",\"v3: Femur Intensity (median)\",\"v3: Miniscus Intensity (median)\",\"v3: Entropy Tibial\",\n",
    "               #   \"v3: Entropy Meniscus\",\"v3: Entropy Femur\",\"v3: Closing Femur\",\"v3: Closing Tibial\",\"v3: Closing Meniscus\",\n",
    "                #  \"v3: Thick Femur X\",\"v3: Thick Femur Y\",\"v3: Thick Femur Z\",\"v3: Thick Tibial Y\",\"v3: Thick Tibial Z\",\n",
    "                 # \"v3: Thick Meniscus X\",\"v3: Thick Meniscus Y\",'y']\n",
    "    \n",
    "df = df[var_of_interest]\n",
    "df[\"id\"]=df.index\n",
    "#df=df.set_index(\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0a815",
   "metadata": {},
   "source": [
    "### Separate into val and train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046da791",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = pd.read_csv(\"matched_15032022\", sep=\",\", header=0)\n",
    "TRAIN = TRAIN.set_index(\"Unnamed: 0\")\n",
    "TRAIN = TRAIN.index\n",
    "\n",
    "VAL = pd.read_csv(\"validation_15032022\", sep=\",\", header=0)\n",
    "VAL = VAL.set_index(\"Unnamed: 0\")\n",
    "VAL = VAL.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdbd6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All: \", df.shape )\n",
    "\n",
    "df[\"id\"] = [int(i[:7]) for i in df.index]\n",
    "\n",
    "# Select validation or training mode VAL or TRAIN\n",
    "train = df.loc[ df['id'].isin(TRAIN)]\n",
    "val = df.loc[~df['id'].isin(TRAIN)]\n",
    "\n",
    "train = train.drop([\"id\"],axis=1)\n",
    "val = val.drop([\"id\"],axis=1)\n",
    "\n",
    "print(\"Train\", train.shape)\n",
    "print(\"Val\", val.shape)\n",
    "train.shape[0]+val.shape[0]\n",
    "\n",
    "y = train[\"y\"]\n",
    "train= train.drop([\"y\"],axis=1)\n",
    "\n",
    "y_val = val[\"y\"]\n",
    "val= val.drop([\"y\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c353de0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= np.array(train)\n",
    "X_val= np.array(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31857041",
   "metadata": {},
   "source": [
    "# correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ba8971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "corr = train.iloc[:, :-1].corr(method='spearman')\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "sns.heatmap(corr, mask=mask, cmap=\"RdBu\", vmin=-1, vmax=1, center=0, linewidths=.5)\n",
    "\n",
    "fig.suptitle('Correlation matrix of Image Features', fontsize=15)\n",
    "ax.text(0.77, 0.2, 'aegis4048.github.io', fontsize=13, ha='center', va='center',\n",
    "         transform=ax.transAxes, color='grey', alpha=0.7)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1db2cf",
   "metadata": {},
   "source": [
    "### Define Stratified k-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ef7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stratified KFOLD \n",
    "n_split=10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_split, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5b028",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16db4e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stratified KFOLD \n",
    "n_split=10\n",
    "mean = 0\n",
    "data =[]\n",
    "preds_stat= np.array([])\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    Xtrain = X[train_index]\n",
    "    ytrain = y[train_index]\n",
    "    Xtest = X[test_index]\n",
    "    ytest = y[test_index]\n",
    "    \n",
    "    #normalize data \n",
    "    m = np.mean(Xtrain,axis=0)\n",
    "    std = np.std(Xtrain, axis =0)\n",
    "    Xtrain = np.array((Xtrain - m )/std)\n",
    "    Xtest = np.array((Xtest - m )/std)\n",
    "    \n",
    "    reg = RandomForestClassifier(max_depth=20).fit(Xtrain, ytrain)\n",
    "    ypred = reg.predict(Xtest)\n",
    "#    ypred = np.where(ypred<0,0, ypred)\n",
    "\n",
    "    preds_stat = np.concatenate([preds_stat,ypred])\n",
    "\n",
    "    print(\"Accuracy Score: \", roc_auc_score(ytest.astype(float), ypred))\n",
    "    #print(\"Accuracy Score!: \",accuracy_score(ytest, ypred.round()))\n",
    "    mean += roc_auc_score(ytest.astype(float), ypred)\n",
    "    data.append(roc_auc_score(ytest.astype(float), ypred))\n",
    "    \n",
    "    \n",
    "print(\"Mean accuracy score: \", mean/n_split)\n",
    "print(\"SSE: \", get_standard_diviation(data) )\n",
    "print(\"All: \", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e76675",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('RF_mri.csv', preds_stat, delimiter=',')   \n",
    "np.savetxt('y_mri.csv', y, delimiter=',')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b7b63a",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bc7415",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.mean(X,axis=0)\n",
    "std = np.std(X, axis =0)\n",
    "X = (X - m )/std\n",
    "X_val = (X_val - m )/std\n",
    "\n",
    "reg = RandomForestClassifier(max_depth=20).fit(X, y)\n",
    "ypred = reg.predict(X_val)\n",
    "\n",
    "print(\"Accuracy Score: \", roc_auc_score(y_val.astype(float), ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a8fb23",
   "metadata": {},
   "source": [
    "# Kfold of Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f7238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = 0\n",
    "data =[]\n",
    "preds_stat=np.array([])\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    Xtrain = X[train_index]\n",
    "    ytrain = y[train_index]\n",
    "    Xtest = X[test_index]\n",
    "    ytest = y[test_index]\n",
    "    \n",
    "    #normalize data \n",
    "    m = np.mean(Xtrain,axis=0)\n",
    "    std = np.std(Xtrain, axis =0)\n",
    "    Xtrain = np.array((Xtrain - m )/std)\n",
    "    Xtest = np.array((Xtest - m )/std)\n",
    "    \n",
    "    reg = LinearRegression().fit(Xtrain, ytrain)\n",
    "    ypred = reg.predict(Xtest)\n",
    "    ypred = np.where(ypred<0,0, ypred)\n",
    "  \n",
    "    preds_stat = np.concatenate([preds_stat,ypred])\n",
    "\n",
    "    print(\"Accuracy Score: \", roc_auc_score(ytest.astype(float), ypred))\n",
    "    mean += roc_auc_score(ytest.astype(float), ypred)\n",
    "    data.append(roc_auc_score(ytest.astype(float), ypred))\n",
    "    \n",
    "print(\"Mean accuracy score: \", mean/n_split)\n",
    "print(\"Confidence interval: \", get_standard_diviation(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115b32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('MLinR_mri.csv', preds_stat, delimiter=',')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f95d92",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "m = np.mean(X,axis=0)\n",
    "std = np.std(X, axis =0)\n",
    "X = (X - m )/std\n",
    "X_val = (X_val - m )/std\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg = reg.fit(X, y)\n",
    "ypred = reg.predict(X_val)\n",
    "\n",
    "print(\"Accuracy Score: \", roc_auc_score(y_val.astype(float), ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29636377",
   "metadata": {},
   "source": [
    "## Make one big Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X,y, test_size=0.20, random_state=True, shuffle=True)\n",
    "\n",
    "m = np.mean(Xtrain,axis=0)\n",
    "std = np.std(Xtrain, axis =0)\n",
    "Xtrain = np.array((Xtrain - m )/std)\n",
    "Xtest = np.array((Xtest - m )/std)\n",
    "\n",
    "reg = LinearRegression().fit(Xtrain, ytrain)\n",
    "ypred = reg.predict(Xtest)\n",
    "ypred = np.where(ypred<0,0, ypred)\n",
    "    \n",
    "print(\"Accuracy Score: \", roc_auc_score(ytest.astype(float), ypred))\n",
    "#print(\"Coefficients: \\n\", reg.coef_)\n",
    "print(\"incept\", reg.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4baa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix( ytest,ypred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9667e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get corefficients\n",
    "params = reg.coef_\n",
    "\n",
    "# Add row to constants\n",
    "newX = pd.DataFrame({\"Constant\":np.ones(len(Xtest))}).join(pd.DataFrame(Xtest))\n",
    "\n",
    "# #calculate std \n",
    "m = np.mean(newX, axis=0)\n",
    "n = len(newX)\n",
    "std = np.sqrt(np.sum((newX-m)**2, axis=0)/(n))\n",
    "\n",
    "#Add incepts\n",
    "params = np.append(reg.intercept_,params)\n",
    "\n",
    "t_values = params/std\n",
    "\n",
    "# set se of incept to 0\n",
    "std[0] = 0\n",
    "std=np.array(std)\n",
    "t_values[0] = 0\n",
    "t_values = np.array(t_values)\n",
    "\n",
    "myDF3 = pd.DataFrame()\n",
    "myDF3[\"Coefficients\"]= params\n",
    "myDF3[\"Standard Errors\"] =std\n",
    "myDF3[\"t values\"] = t_values\n",
    "names=[\"incept\"]+list(df.drop(columns=[\"y\",\"id\"]))\n",
    "myDF3=myDF3.set_index(pd.Index(names))\n",
    "myDF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89567fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = myDF3[\"t values\"][1:]\n",
    "n=len(importance)//3 #round((len(importance))/2)\n",
    "# Get variables, connect to weights (#Note remove id and labels)\n",
    "variables =[i[4:] for i in myDF3.index[1:]]\n",
    "\n",
    "# plot histograms\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.bar([x for x in range(len(importance[:n]))], importance[:n], alpha=0.5, color=\"b\",label=\"V1\",edgecolor=None)\n",
    "plt.xticks([x for x in range(len(importance[:n]))], variables[:n], rotation =90)\n",
    "plt.bar([x for x in range(len(importance[n:2*n]))], importance[n:2*n], alpha=0.5, color=\"g\",label=\"V2\",edgecolor=None)\n",
    "plt.xticks([x for x in range(len(importance[n:2*n]))], variables[n:2*n], rotation =90)\n",
    "plt.bar([x for x in range(len(importance[2*n:]))], importance[2*n:], alpha=0.5, color=\"r\",label=\"V3\",edgecolor=None)\n",
    "plt.xticks([x for x in range(len(importance[2*n:]))], variables[2*n:], rotation =90)\n",
    "plt.plot(range(n),np.zeros(n),c=\"black\")\n",
    "\n",
    "plt.grid(True, linestyle='-.')\n",
    "#plt.ylim([0,1])\n",
    "#plt.yscale('symlog')\n",
    "plt.tick_params(labelcolor='r', labelsize=20, width=3)\n",
    "plt.savefig(\"allfeat\")\n",
    "plt.legend(loc=\"best\",fontsize=\"xx-large\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bf5afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "245c003b",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d9219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_list = []\n",
    "preds_stat = np.array([])\n",
    "\n",
    "mean = 0\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    Xtrain = X[train_index]\n",
    "    ytrain = y[train_index]\n",
    "    Xtest = X[test_index]\n",
    "    ytest = y[test_index]\n",
    "    \n",
    "    m = np.mean(Xtrain,axis=0)\n",
    "    std = np.std(Xtrain, axis =0)\n",
    "    Xtrain = (Xtrain - m )/std\n",
    "    Xtest = (Xtest - m )/std\n",
    "    \n",
    "    Log_reg = LogisticRegression(max_iter=20000).fit(Xtrain, ytrain)\n",
    "    ypred = Log_reg.predict(Xtest)\n",
    "    y_pred = Log_reg.predict_proba(Xtest)     \n",
    "\n",
    "    preds_stat = np.concatenate([preds_stat,ypred])\n",
    "\n",
    "    print(\"Accuracy Score: \", roc_auc_score(ytest.astype(float), y_pred[:,1]))\n",
    "    mean +=roc_auc_score(ytest.astype(float), y_pred[:,1])\n",
    "    mean_list.append(roc_auc_score(ytest.astype(float), y_pred[:,1]))\n",
    "    \n",
    "print(\"Mean accuracy score: \", mean/n_split)  \n",
    "print(\"Confidence interval: \", get_standard_diviation(mean_list))\n",
    "\n",
    "np.savetxt('MLogR_mri.csv', preds_stat, delimiter=',')   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b58b48",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5f8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "m = np.mean(X,axis=0)\n",
    "std = np.std(X, axis =0)\n",
    "X = (X - m )/std\n",
    "X_val = (X_val - m )/std\n",
    "\n",
    "\n",
    "#Pred\n",
    "reg = LogisticRegression(max_iter=1000000000000000)\n",
    "reg = reg.fit(X, y)\n",
    "ypred = reg.predict(X_val)\n",
    "\n",
    "print(\"Accuracy Score: \", roc_auc_score(y_val.astype(float), ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84be0167",
   "metadata": {},
   "source": [
    "# LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make stratified KFOLD \n",
    "mean = 0\n",
    "mean_list =[]\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    Xtrain = X[train_index]\n",
    "    ytrain = y[train_index]\n",
    "    Xtest = X[test_index]\n",
    "    ytest = y[test_index]\n",
    "    \n",
    "    m = np.mean(Xtrain,axis=0)\n",
    "    std = np.std(Xtrain, axis =0)\n",
    "    Xtrain = (Xtrain - m )/std\n",
    "    Xtest = (Xtest - m )/std\n",
    "    \n",
    "    reg_las = linear_model.Lasso(0.03)\n",
    "    reg_las.fit(Xtrain, ytrain) \n",
    "    ypred = reg_las.predict(Xtest)\n",
    "\n",
    "    print(\"Accuracy Score: \", roc_auc_score(ytest.astype(float), ypred))\n",
    "    mean +=roc_auc_score(ytest.astype(float), ypred)\n",
    "    mean_list.append(roc_auc_score(ytest.astype(float), ypred))\n",
    "\n",
    "print(\"Mean accuracy score: \", mean/n_split)    \n",
    "print(\"Confidence Interval: \", get_standard_diviation(mean_list) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get corefficients\n",
    "params = reg_las.coef_\n",
    "\n",
    "# Add row to constants\n",
    "newX = pd.DataFrame({\"Constant\":np.ones(len(Xtest))}).join(pd.DataFrame(Xtest))\n",
    "\n",
    "# #calculate std \n",
    "m = np.mean(newX, axis=0)\n",
    "n = len(newX)\n",
    "std = np.sqrt(np.sum((newX-m)**2, axis=0)/(n))\n",
    "\n",
    "#Add incepts\n",
    "params = np.append(reg_las.intercept_,params)\n",
    "\n",
    "t_values = params/std\n",
    "\n",
    "# set se of incept to 0\n",
    "std[0] = 0\n",
    "std=np.array(std)\n",
    "t_values[0] = 0\n",
    "t_values = np.array(t_values)\n",
    "\n",
    "myDF3 = pd.DataFrame()\n",
    "myDF3[\"Coefficients\"]= params\n",
    "myDF3[\"Standard Errors\"] =std\n",
    "myDF3[\"t values\"] = t_values\n",
    "names=[\"incept\"]+list(df.drop(columns=[\"y\",\"id\"]))\n",
    "myDF3=myDF3.set_index(pd.Index(names))\n",
    "myDF3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cdd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = myDF3[\"t values\"][1:]\n",
    "n=len(importance)//3#round((len(importance))/2)\n",
    "# Get variables, connect to weights (#Note remove id and labels)\n",
    "variables =[i[4:] for i in myDF3.index[1:]]\n",
    "\n",
    "# plot histograms\n",
    "plt.figure(figsize=(30, 10))\n",
    "plt.bar([x for x in range(len(importance[:n]))], importance[:n], alpha=0.5, color=\"b\",label=\"V1\",edgecolor=None)\n",
    "plt.xticks([x for x in range(len(importance[:n]))], variables[:n], rotation =90)\n",
    "plt.bar([x for x in range(len(importance[n:2*n]))], importance[n:2*n], alpha=0.5, color=\"g\",label=\"V2\",edgecolor=None)\n",
    "plt.xticks([x for x in range(len(importance[n:2*n]))], variables[n:2*n], rotation =90)\n",
    "plt.bar([x for x in range(len(importance[2*n:]))], importance[2*n:], alpha=0.5, color=\"r\",label=\"V3\",edgecolor=None)\n",
    "plt.xticks([x for x in range(len(importance[2*n:]))], variables[2*n:], rotation =90)\n",
    "#plt.yscale('symlog')\n",
    "plt.plot(range(0,n+1), np.zeros(n+1), c=\"black\")\n",
    "plt.grid(True, linestyle='-.')\n",
    "#plt.ylim([-0.005,0.006])\n",
    "plt.tick_params(labelcolor='r', labelsize=20, width=3)\n",
    "plt.legend(loc=\"best\",fontsize=\"xx-large\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe3a6bd",
   "metadata": {},
   "source": [
    "### Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.Lasso(0.03)\n",
    "reg = reg.fit(X, y)\n",
    "ypred = reg.predict(X_val)\n",
    "\n",
    "print(\"Accuracy Score: \", roc_auc_score(y_val.astype(float), ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b27a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cbbc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9b0412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35609eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
